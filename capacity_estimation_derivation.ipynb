{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to determine for a given $M$, $N$, $q$, and $L$, how many (on average) sets of $L$ non-overlapping associations can be stored and recalled in a network. We will normalize by the number $N^*_L$ of possible sets of $L$ non-overlapping associations.\n",
    "\n",
    "This normalized \"capacity\" is given by\n",
    "\n",
    "$$E[C(M, N, q, L)] = E_W\\left[\\cfrac{1}{N^*_L}\\sum\\limits_{s_L} \\mathbb{1}\\left[s_L \\textrm{ is recallable}|M, N, q\\right]\\right] = \\cfrac{1}{N^*_L}\\sum\\limits_{s_L} E_W\\left[\\mathbb{1}\\left[s_L \\textrm{ is recallable}\\right]\\right]$$\n",
    "\n",
    "$$= \\cfrac{N^*_L}{N^*_L}p(s_L \\textrm{ is recallable}|M, N, q) = p(s_L \\textrm{ is recallable}|M, N, q)$$\n",
    "\n",
    "where the last step arises because the probability of a set $s_L$ of associations being recallable doesn't depend on which items are in the associations, because of the homogeneous randomness throughout the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without loss of generality, we can therefore assume that $s_L = \\{(1, 2), (3, 4), ... (2L-1, 2L)\\}$. Then, denoting $V_j$ to be the set of association units connecting to item unit $j$, we can expand\n",
    "\n",
    "$$p(s_L \\textrm{ is recallable}|M, N, q) = \\sum\\limits_{V_1, ..., V_{2L}}p(V_1, ..., V_{2L})p(s_L \\textrm{ is recallable}|M, N, q, V_1, ..., V_{2L}).$$\n",
    "\n",
    "Next, let $A$ be the set of association/memory units moved to their hyperexcitable state after storage of the associations. This is given by \n",
    "\n",
    "$$A = \\bigcup\\limits_{i = 1}^L \\left(V_{2i - 1}\\bigcap V_{2i}\\right).$$\n",
    "\n",
    "Then, we can state that the $i$-th pair in $s_L$ is recallable if:\n",
    "\n",
    "$$\\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i - 1} \\bigcap A \\bigcap V_j \\right\\vert \\textrm{ and } \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i} \\bigcap A \\bigcap V_j \\right\\vert \\textrm{ for all } j \\neq 2i-1, 2i.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is deterministic for $j <= L$ and probabilistic for $j > L$, we can write\n",
    "\n",
    "$$p(s_L \\textrm{ is recallable}|M, N, q, V_1, ..., V_{2L}) = f(V_1, ..., V_{2L})g(M, N, q, V_1, ..., V_{2L})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$f(V_1, ..., V_{2L}) = \\prod\\limits_{i = 1}^L \\mathbb{1}\\left[ \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i - 1} \\bigcap A \\bigcap V_j \\right\\vert \\textrm{ and } \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i} \\bigcap A \\bigcap V_j \\right\\vert \\forall j \\leq 2L, \\neq 2i-1, 2i\\right]$$\n",
    "\n",
    "and is deterministic, and\n",
    "\n",
    "$$g(M, N, q, V_1, ..., V_{2L}) = p\\left( \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i - 1} \\bigcap A \\bigcap V_j \\right\\vert \\textrm{ and } \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i} \\bigcap A \\bigcap V_j \\right\\vert \\forall j > 2L, i \\leq 2L \\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since all the $V_j$ are sampled i.i.d. for $j > 2L$, we can simplify to\n",
    "\n",
    "$$g(M, N, q, V_1, ..., V_{2L}) = h(N, q, V_1, ..., V_{2L})^{M - 2L}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$h(N, q, V_1, ..., V_{2L}) = p\\left( \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i - 1} \\bigcap A \\bigcap V_j \\right\\vert \\textrm{ and } \\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i} \\bigcap A \\bigcap V_j \\right\\vert \\forall i \\leq 2L \\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we have that\n",
    "\n",
    "$$p(s_L \\textrm{ is recallable}|M, N, q) = \\sum\\limits_{V_1, ..., V_{2L}}p(V_1, ..., V_{2L})f(V_1, ..., V_{2L})h(N, q, V_1, ..., V_{2L})^{M - 2L}.$$\n",
    "\n",
    "If $f(V_1, ..., V_{2L})h(N, q, V_1, ..., V_{2L})^{M - 2L}$ can be computed analytically, then we can approximate $p(s_L \\textrm{ is recallable}|M, N, q)$ via a standard Monte Carlo estimation, since we can sample easily from $p(V_1, ..., V_{2L})$. However, while $f(V_1, ..., V_{2L})$ is computable via a small matrix multiplication, $h(N, q, V_1, ..., V_{2L})$ is not so simple, since it is equal to the following joint probability distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h(N, q, V_1, ..., V_{2L}) = \\\\ p\\left(\n",
    "\\left\\vert V_1 \\bigcap V_2\\right\\vert > \\left\\vert V_1 \\bigcap A \\bigcap V_j \\right\\vert, \\left\\vert V_1 \\bigcap V_2 \\right\\vert > \\left\\vert V_2 \\bigcap A \\bigcap V_j \\right\\vert, \\\\\n",
    "\\left\\vert V_3 \\bigcap V_4\\right\\vert > \\left\\vert V_3 \\bigcap A \\bigcap V_j \\right\\vert, \\left\\vert V_3 \\bigcap V_4 \\right\\vert > \\left\\vert V_4 \\bigcap A \\bigcap V_j \\right\\vert, \\\\\n",
    "\\vdots \\\\\n",
    "\\left\\vert V_{2L-1} \\bigcap V_{2L}\\right\\vert > \\left\\vert V_{2L-1} \\bigcap A \\bigcap V_j \\right\\vert, \\left\\vert V_{2L-1} \\bigcap V_{2L} \\right\\vert > \\left\\vert V_{2L} \\bigcap A \\bigcap V_j \\right\\vert\\right)$$\n",
    "\n",
    "and any errors in estimating $h$ will be amplified by the power of $M - 2L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, it happens to be the case that this joint distribution is always greater than or equal to the product of the corresponding marginals:\n",
    "\n",
    "$$h(N, q, V_1, ..., V_{2L}) \\geq \\prod\\limits_{i = 1}^L p\\left(\n",
    "\\left\\vert V_{2i - 1} \\bigcap V_{2i}\\right\\vert > \\left\\vert V_{2i-1} \\bigcap A \\bigcap V_j \\right\\vert\\right) p\\left(\\left\\vert V_{2i - 1} \\bigcap V_{2i} \\right\\vert > \\left\\vert V_{2i} \\bigcap A \\bigcap V_j \\right\\vert\\right) = h^*(N, q, V_1, ..., V_{2L}).$$\n",
    "\n",
    "The intuition behind this is that knowing that $\\left\\vert V_j \\bigcap X_1 \\right\\vert < y_1$ won't ever decrease the probability that $\\left\\vert V_j \\bigcap X_2 \\right\\vert < y_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculating $p\\left(\n",
    "\\left\\vert V_1 \\bigcap V_2\\right\\vert > \\left\\vert V_1 \\bigcap A \\bigcap V_j \\right\\vert\\right)$, for example, is quite straightforward, since each element of $V_j$ is sampled independently. Specifically, if we rewrite $y_{12} = \\left\\vert V_1 \\bigcap V_2\\right\\vert$ and $Z_1 = V_1 \\bigcap A$, then\n",
    "\n",
    "$$p\\left(\n",
    "\\left\\vert V_1 \\bigcap V_2\\right\\vert > \\left\\vert V_1 \\bigcap A \\bigcap V_j \\right\\vert\\right) = p\\left(y_{12} > \\left\\vert V_j \\bigcap Z_1 \\right\\vert\\right) = p\\left(\\left\\vert V_j \\bigcap Z_1 \\right\\vert < y_{12}\\right),$$\n",
    "\n",
    "but this is just given by \n",
    "\n",
    "$$p\\left(\\left\\vert V_j \\bigcap Z_1 \\right\\vert < y_{12}\\right) = \\sum\\limits_{\\left\\vert V_j \\bigcap Z_1 \\right\\vert = 0}^{y_{12} - 1} \\textrm{Binomial}\\left(\\left\\vert V_j \\bigcap Z_1 \\right\\vert | \\left\\vert Z_1 \\right\\vert, q\\right) = \n",
    "\\textrm{CDF}_{\\textrm{Bi}}\\left(y_{12} - 1 | n=\\left\\vert Z_1 \\right\\vert, p=q\\right)$$\n",
    "\n",
    "which is easy to compute exactly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
