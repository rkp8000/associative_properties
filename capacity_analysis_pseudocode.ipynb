{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenge in computing this quantity will be retaining numerical precision, since our motivating hypothesis is that $p(s_L \\textrm{ recalled correctly}|M, N, q)$ might often be very close to unity. In fact, it might even be exponentially close to unity, so it could be useful to think instead in terms of the error, and specifically its logarithm. We can adjust our calculation accordingly by noting:\n",
    "\n",
    "$$p(s_L \\textrm{ recalled incorrectly}|M, N, q) = 1 - p(s_L \\textrm{ recalled correctly}|M, N, q) \\\\ \\approx \\cfrac{1}{N_{MC}}\\sum\\limits_{V_1, ..., V_{2L}}(1 - p(s_L \\textrm{ recalled correctly}|V_1, ..., V_{2L}, M, N, q)) \\leq \\\\\n",
    "\\cfrac{1}{N_{MC}}\\sum\\limits_{V_1, ..., V_{2L}}\\left[1 - f(V_1, ..., V_{2L})h(V_1, ..., V_{2L}, N, q)^{M-2L}\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the logarithm we then have:\n",
    "\n",
    "$$\\log p(s_L \\textrm{ recalled incorrectly}|M, N, q) \\leq \\\\\n",
    "-\\log N_{MC} + \\log\\sum\\limits_{V_1, ..., V_{2L}}\\left[1 - f(V_1, ..., V_{2L})h(V_1, ..., V_{2L}, N, q)^{M-2L}\\right].$$\n",
    "\n",
    "However, if any of terms in the sum is rounded to zero from numerical imprecision, the entire sum will be evaluated to be $-\\infty$, preventing us from exploring the dependence of error on $N, q, M$ and $L$ when it is already very low. To deal with this, we will instead calculate the logarithm of the terms inside the sum, along with the fact that even though there's not an obviously useful mathematical identity expressing the logarithm of a sum as a function of a the logarithm of its individual terms, computationally this can be done very practically while still avoiding significant numerical errors (see appendix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine\n",
    "\n",
    "$$\\log\\left[1 - f(V_1, ..., V_{2L})h(V_1, ..., V_{2L}, N, q)^{M-2L}\\right]$$\n",
    "\n",
    "we first recall that $f$ is always either $0$ or $1$, so when it is $0$ this quantity will equal $0$. When $f = 1$ (which hypothesize to often be true) we must consider two numerical cases: (1) $h^{M-2L}$ is sufficiently less than unity that numerical errors are insignificant, or (2) $h^{M-2L}$ is close enough to unity that numerical errors might cause a problem.\n",
    "\n",
    "In case (1) we can simply calculate $\\log\\left[1 - h^{M-2L}\\right]$. In case (2) we must remember that we are fundamentally trying to get an accurate description of how close $h^{M - 2L}$ is to $1$, and since it is presumably very close, we would like to use the logarithm to maintain accuracy.\n",
    "\n",
    "To proceed, we use the following Taylor expansion, valid when $1 - x < \\epsilon$, i.e., $x$ is very close to unity:\n",
    "\n",
    "$$1 - x \\approx -\\log x \\implies \\log(1 - x) \\approx \\log(-\\log x) $$\n",
    "\n",
    "or in our specific situation, since in case (2) we have that $h^{M-2L}$ is very close to unity,\n",
    "\n",
    "$$\\log(1 - h^{M-2L}) \\approx \\log(-\\log h^{M-2L}) = \\log\\left(-\\log\\left(\\prod\\limits_{i=1}^{2L}c_i\\right)^{M-2L}\\right) = \\\\\n",
    "\\log\\left(-(M - 2L)\\left(\\sum\\limits_{i=1}^{2L}\\log c_i\\right)\\right) =\n",
    "\\log(M-2L) + \\log\\left(-\\left(\\sum\\limits_{i=1}^{2L}\\log c_i\\right)\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final issue we must address is that $c_i$ may be so close to unity that numerical errors in calculating its log will cause us to lose desired precision. When this is the case, i.e., when $c_i > 1 - \\epsilon$, it can be more practical to use the log of the *survival function* $\\log s_i$, where $s_i = 1 - c_i$ but can be calculated without any significant loss of precision when $c_i > 1 - \\epsilon$. To use this to our advantage, we note that when $c_i > 1 - \\epsilon$ we have\n",
    "\n",
    "$$\\log c_i = \\log(1 - s_i) \\approx -s_i.$$\n",
    "\n",
    "Thus, when calculating the inner sum we simply need to replace $\\log c_i$ by $-s_i$ whenever $c_i > 1 - \\epsilon$. This final adjustment allows us to calculate $\\log(1 - h^{M-2L})$ without any significant loss of accuracy. And when all is said and done the calculation of our upper bound on the log error\n",
    "\n",
    "$$\\log p(s_L \\textrm{ recalled incorrectly}|M, N, q)$$\n",
    "\n",
    "can be completed in $O(N_{MC}L)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: we can get a rough estimate for the log error $\\log(1 - h^{M-2L})$ by noticing that the survival function, which is a stand-in for $-\\log c_i$, will decrease roughly exponentially with $N$, such that the error equation is roughly:\n",
    "\n",
    "$$\\log(M - 2L) + \\log(\\alpha^N) = \\log(M - 2L) - \\alpha'N$$\n",
    "\n",
    "since $\\alpha < 1$.\n",
    "This means that to keep the error under a fixed amount, M should be able to grow exponentially faster than $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode\n",
    "\n",
    "We can summarize the final algorithm for calculating the upper bound on $\\log p(s_L \\textrm{ recalled incorrectly}|M, N, q)$ as follows.\n",
    "\n",
    "#### Principal routines\n",
    "\n",
    "```python\n",
    "LOG_EPSILON = -9*log(10)\n",
    "\n",
    "def max_items_low_error(max_log_error, N_MC, N, L, q, R=None):\n",
    "    \"\"\"\n",
    "    Calculate the (log) max number of items that a set of\n",
    "    associative memory units can support.\n",
    "    \"\"\"\n",
    "    \n",
    "    fs, log_neg_log_hs = calc_fs_and_log_neg_log_hs_asym(N_MC, N, L, q, R)\n",
    "    \n",
    "    # define function to be solved\n",
    "    def func_to_solve(log_m):\n",
    "        \"\"\"Increasing function of log_m.\"\"\"\n",
    "    \n",
    "        log_m_minus_2l = log_m if log(2*l) - log_m < LOG_EPSILON else log(exp(log_m) - 2*l)\n",
    "\n",
    "        log_sum_terms = np.nan * np.zeros(len(vs))\n",
    "        approx_mask = log_m_minus_2l + log_neg_log_h < LOG_EPSILON\n",
    "\n",
    "        log_sum_terms[approx_mask] = log_m_minus_2l + log_neg_log_hs[approx_mask]\n",
    "        h_to_m_minus_2l = exp(-exp(log_neg_log_h[~approx_mask] + log_m_minus_2l))\n",
    "        log_sum_terms[~approx_mask] = log(1 - h_to_m_minus_2l)\n",
    "\n",
    "        f_0_mask = (fs == 0)\n",
    "        log_sum_terms[f_0_mask] = 0\n",
    "        \n",
    "        return log_sum(log_sum_terms) - max_log_error\n",
    "        \n",
    "    # determine initial optimization bracket\n",
    "    log_m_ub = log(2L)\n",
    "    if func_to_solve(log_m_ub) >= 0: return -inf\n",
    "    \n",
    "    log_m_ub += 1\n",
    "    while func_to_solve(log_m_ub) < 0: log_m_ub += 1\n",
    "    \n",
    "    log_m_lb = log_m_ub - 1\n",
    "    \n",
    "    # find the root of the equation\n",
    "    \n",
    "    return brentq(func_to_solve, log_m_lb, log_m_ub)\n",
    "    \n",
    "\n",
    "def log_upper_error_bound(log_ms, N_MC, N, L, q, R=None):\n",
    "    \"\"\"\n",
    "    Calculate the log of the upper bound on the expected error\n",
    "    for several different numbers of item units.\n",
    "    \"\"\"\n",
    "\n",
    "    fs, log_neg_log_hs = calc_fs_and_log_neg_log_hs_asym(N_MC, N, L, q, R)\n",
    "        \n",
    "    # calculate the log of each term in the sum,\n",
    "    # using approximations where necessary\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for log_m in log_ms:\n",
    "    \n",
    "        log_m_minus_2l = log_m if log(2*l) - log_m < LOG_EPSILON else log(exp(log_m) - 2*l)\n",
    "\n",
    "        log_sum_terms = np.nan * np.zeros(len(vs))\n",
    "\n",
    "        approx_mask = log_m_minus_2l + log_neg_log_h < LOG_EPSILON\n",
    "\n",
    "        log_sum_terms[approx_mask] = log_m_minus_2l + log_neg_log_hs[approx_mask]\n",
    "        h_to_m_minus_2l = exp(-exp(log_neg_log_h[~approx_mask] + log_m_minus_2l))\n",
    "        log_sum_terms[~approx_mask] = log(1 - h_to_m_minus_2l)\n",
    "\n",
    "        f_0_mask = (fs == 0)\n",
    "        log_sum_terms[f_0_mask] = 0\n",
    "    \n",
    "        errors.append(log_sum(log_sum_terms))\n",
    "        \n",
    "    return errors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subroutines\n",
    "\n",
    "```python\n",
    "def calc_fs_and_log_neg_log_hs(N, L, q, N_MC, R):\n",
    "\n",
    "    if R == None: # symmetric case\n",
    "    \n",
    "        vs = sample_vs(N_MC, N, L, q)\n",
    "        xs_all, rs_all = zip(*[calc_xs_and_rs(v) for v in vs])\n",
    "        \n",
    "    else: # asymmetric case\n",
    "    \n",
    "        vs, us = sample_vs_and_us(N_MC, N, L, q, R)\n",
    "        xs_all, rs_all = zip(*[calc_xs_and_rs(v, u) for v, u in zip(vs, us)])\n",
    "    \n",
    "    x_sizes_all = [np.sum(xs, axis=1) for xs in xs_all]\n",
    "    \n",
    "    fs = [calc_f(v, xs, rs) for v, xs, rs in zip(vs, xs_all, rs_all)]\n",
    "    log_neg_log_hs = [\n",
    "        calc_log_neg_log_h(x_sizes, rs, q) \n",
    "        for x_size, rs in zip(x_sizes_all, rs_all)\n",
    "    ]\n",
    "    \n",
    "    return np.array(fs), np.array(log_neg_log_hs)\n",
    "    \n",
    "def sample_vs(n_mc, n, l, q):\n",
    "\n",
    "    return (np.random.rand(n_mc, 2*l, n) < q).astype(int)\n",
    "    \n",
    "def sample_vs_and_us(n_mc, n, l, q, R):\n",
    "\n",
    "    vs = sample_vs(n_mc, n, l, q)\n",
    "    d = (1 - q*R) / (1 - q)\n",
    "    us[vs.astype(bool)] = (np.random.rand(vs.sum()) < q*R).astype(int)\n",
    "    us[~vs.astype(bool)] = (np.random.rand(vs.sum()) < q*d).astype(int)\n",
    "    \n",
    "    return vs, us\n",
    "    \n",
    "def calc_xs_and_rs(v, u=None):\n",
    "\n",
    "    # calculate pairwise intersections\n",
    "    if u is None: isctns = [v[ctr] * v[ctr + 1] for ctr in range(0, len(v), 2)]\n",
    "    else: isctns = [u[ctr] * u[ctr + 1] for ctr in range(0, len(u), 2)]\n",
    "        \n",
    "    isctns = np.array([val for pair in zip(isctns, isctns) for val in pair])\n",
    "    \n",
    "    # calculate maintained set and xs\n",
    "    maintained = np.sum(isctns, axis=0)\n",
    "    \n",
    "    xs = [np.sum(v[ctr] * maintained) for ctr in range(len(v))]\n",
    "    rs = isctns.sum(axis=1)\n",
    "    \n",
    "    return xs, rs\n",
    "    \n",
    "def calc_f(v, xs, rs):\n",
    "\n",
    "    if len(v) <= 2: return 1\n",
    "    \n",
    "    for ctr_0, (x, r) in enumerate(zip(xs, rs)):\n",
    "        \n",
    "        # pair to which item belongs\n",
    "        pair = (ctr_0 - 1, ctr_0) if x % 2 else (ctr_0, ctr_0 + 1)\n",
    "        \n",
    "        for ctr_1 in [j for j in range(len(vs)) if j not in pair]:\n",
    "        \n",
    "            if (v[ctr_1] * x).sum() >= r: return 0\n",
    "            \n",
    "    return 1\n",
    "    \n",
    "def calc_log_neg_log_h(x_sizes, rs, q):\n",
    "\n",
    "    # calculate the log survival function for each x, r\n",
    "    log_sfs = binom_log_sf(rs, x_sizes, q)\n",
    "    \n",
    "    # replace log_sfs by log(-log_cdf) when log_sf is too big for taylor approx\n",
    "    mask = log_sfs > LOG_EPSILON\n",
    "    log_sfs[mask] = log(-binom_log_cdf(rs[mask], x_sizes[mask], q))\n",
    "    \n",
    "    # calculate log of sum of sfs in terms of log_sfs\n",
    "    return log_sum(log_sfs)\n",
    "\n",
    "def log_sum(log_xs):\n",
    "\n",
    "    ... calculate the logarithm of a sum given the logarithms of its terms \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code tests\n",
    "\n",
    "How to convince oneself the code works:\n",
    "\n",
    "Potentially testable functions:\n",
    "\n",
    "* `calc_log_mc_sum`\n",
    "    * provide some example values and make sure approximation works correctly\n",
    "* `calc_fs_and_log_neg_log_hs`\n",
    "    * not a good way to test this, but it's fairly simple so we can trust it...\n",
    "* `sample_vs`\n",
    "    * test with small and large `q`\n",
    "* `sample_vs_and_us`\n",
    "    * test with small and large `q` and with R = 0, 1/q, 1/2q\n",
    "* `calc_f`\n",
    "    * test with a few examples\n",
    "* `calc_log_neg_log_hs`\n",
    "    * test with a few examples in the case of using the approximation and not\n",
    "* `calc_xs_and_rs`\n",
    "    * test with examples when u = None and otherwise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
